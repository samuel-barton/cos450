			                  +--------------------+
       	       	        |    COS 450/550     |
			                  | PROJECT 1: THREADS |
			                  |   DESIGN DOCUMENT  |
			                  +--------------------+
				   
---- GROUP ----

          _________________________________________
  ________|                                         |_______
  \       | Robert Miller <robert.miller@maine.edu> |      /
   \      | Samuel Barton <samuel-barton@maine.edu> |     /
   /      |_________________________________________|     \
  /__________)                                   (_________\



---- PRELIMINARIES ----

>> If you have any preliminary comments on your submission, notes for the
>> TAs, or extra credit, please give them here.

>> Please cite any offline or online sources you consulted while
>> preparing your submission, other than the Pintos documentation, course
>> text, lecture notes, and course staff.

			     ALARM CLOCK
			     ===========

---- DATA STRUCTURES ----

>> A1: Copy here the declaration of each new or changed `struct' or
>> `struct' member, global or static variable, `typedef', or
>> enumeration.  Identify the purpose of each in 25 words or less.

thread.c 

  /* list that holds threads that have been put to sleep */ 
  static struct list sleep_list;

thread.h : 

  /* sleep list element */ 
  struct list_elem sleep_elem;              

  /* Tick to wake up on. if (timer_tickes == thread->wakeup_tick) the thread is woke up */
  uint64_t wakeup_tick;



---- ALGORITHMS ----

>> A2: Briefly describe what happens in a call to timer_sleep(),
>> including the effects of the timer interrupt handler.

Here is an explanation of the flow of operations when timer_sleep() is called: 

timer_sleep (int64_t ticks) :
  -parameter represents how many ticks the thread should be asleep
  -assert that interrupts are on
  -check to make sure that ticks are >= 0
  -calculates wakeup_tick by adding ticks to the current tick (timer_ticks())
  -calls new thread_sleep method in thread.c that takes wakeup_tick as a parameter
thread_sleep(int64_t wakeup_ticks) : 
  -sets 0 as a minimum value for wakeup_ticks (in other words, if <= 0 wake up immediately)
  -set the wakeup_tick value of the running thread to the parameter
  -disable interrupts
  -insert running thread into sleeping list by wakeup_tick in ascending order
  -block the running thread by calling thread_block() method
  -enable interrupts 
thread_block() : 
  -assert that interrupts are off
  -set status of running thread to THREAD_BLOCKED
  -call schedule() method to start running next thread 

>> A3: What steps are taken to minimize the amount of time spent in
>> the timer interrupt handler?

  We minimize the time spent with interrupts disabled, and we only use one time-consuming operation,
namely the list_insert_ordered on our wait list.

---- SYNCHRONIZATION ----

>> A4: How are race conditions avoided when multiple threads call
>> timer_sleep() simultaneously?

  The timer_sleep() method quickly calculates the ticks to wake up on and passes that to thread_sleep(),
which promptly disables interrupts before it inserts the running thread in the sleep list and blocks the thread.
Interrupts should be disabled during the insertion into lists as well as when you are switching running threads, 
which is a direct result of blocking the running thread. 


>> A5: How are race conditions avoided when a timer interrupt occurs
>> during a call to timer_sleep()?

  Race conditions are avoided by use of enabling and disabling interrupts. When manipulating a list, interrupts are
disabled so a thread finishes the manipulation before any interrupt can occur that may require use of the same list. 
Additionally, interrupts are disabled when switching running threads to minimize cpu idle time. 


---- RATIONALE ----

>> A6: Why did you choose this design?  In what ways is it superior to
>> another design you considered?

  We chose this design as it is efficient and minimizes the time that interrupts are disabled. Our initial 
implementation attempted to solve this problem without disabling interrupts at all which lead to race issues. Our
second implementation was too cavalier with interrupts are was inefficient. We found a middle ground which both ensured
that our data was processed in the order we intended and was reasonably efficient. 

			 PRIORITY SCHEDULING
			 ===================

---- DATA STRUCTURES ----

>> B1: Copy here the declaration of each new or changed `struct' or
>> `struct' member, global or static variable, `typedef', or
>> enumeration.  Identify the purpose of each in 25 words or less.



thread.h :

  /* Boolean value for whether or not this thread has received donations, which 
     is used to make the priority reassessment process more efficient */
  bool donatee;

  /* List of threads that currently have their priority donated to this thread */
  struct list donators;

  /* Donator list element. Used if this thread is a donator for a different thread */
  struct list_elem donate_elem;

  /* Holds the value of the thread before any donations occurred. A thread is defaulted back
     to this once their donation list is empty */ 
  int original_priority; 



>> B2: Explain the data structure used to track priority donation.
>> Use ASCII art to diagram a nested donation.  (Alternately, submit a
>> .png file.)

There are two lists and an integer which make up the "data structure" for 
priority donation. The first list is the list of the threads which have donated
there priority to each individual thread. The second list is the list of all
threads with donated priority. The integer keeps track of the threads undonated
priority so that when all donations have been cleared we can set the thread
back to its undonated priority.

At time t1

thread_low:2                thread_med:2             
    |  +--------------+          |  +------+
    +--| thread_med:2 |          +--| NULL |
    |  +--------------+             +------+
    +-- old_priority = 1          

at time t2

thread_low:2                thread_med:3             
    |  +--------------+          |  +---------------+
    +--| thread_med:3 |          +--| thread_high:3 |
    |  +--------------+          |  +---------------+
    +-- old_priority = 1         +-- old_priority = 2

The call to thread_donate_priority() for thread_med causes the donatee_list's
threads to be checked over and when this occurs the newly changed priority of
thread_med will be refleted in thread_low.

at time t3

thread_low:3                thread_med:3             
    |  +--------------+          |  +---------------+
    +--| thread_med:3 |          +--| thread_high:3 |
    |  +--------------+          |  +---------------+
    +-- old_priority = 1         +-- old_priority = 2

---- ALGORITHMS ----

>> B3: How do you ensure that the highest priority thread waiting for
>> a lock, semaphore, or condition variable wakes up first?

  We insert threads into the lists by order of priority. If there is an event that changes priority
of a donator, then we loop through the list of donatees to reassess their priority. When a lock is released,
the list item in the front of the semphore, which contains the highest priority thread, is unblocked. 

>> B4: Describe the sequence of events when a call to lock_acquire()
>> causes a priority donation.  How is nested donation handled?

lock_acquire ( lock )
  -if a thread already holds the lock and has a priority lower than 
   current thread's priority, call thread_donate_priority( lock->holder )
  -down the semaphore
  -set current thread to be the lock holder
  
thread_donate_priority( thread donatee )
  -takes the thread to be donated to as input
  -if the thread to be donated to isn't already flagged as a donatee, flag it as one
  -disable interrupts 
  -insert the current thread into the donators list of the donatee thread
  -reassess the priority of the donatee thread
    -if the donators list is empty, set to the original priority value. Otherwise, set to the maximum priority  
     value of the threads on the donators list
  -renable interrupts

The, unfortunately unimplemented, design we chose to handle nested donations 
would work as follows. There would be another list, like the ready list, in 
thread.c and this list would hold all donatee threads. I.e. all threads which 
have a donated priority. Each time one of the priority changing methods is 
called, each thread on that list has its list of donator threads checked to
ensure that it's priority is still the maximum priority of the threads in the 
donator list. This way, nesting could be done as deeply as necessary.


>> B5: Describe the sequence of events when lock_release() is called
>> on a lock that a higher-priority thread is waiting for.

lock_release ( lock )
  -if there are any threads waiting on the lock, remove all threads from the lock holder's donator list
   that are also on the lock's semaphore's waiting list
  -set the holder of the lock to be null
  -reassess the priorities of all threads
  -up the semaphore which unblocks the waiting thread of higher priority
  -with a thread of higher priority now ready, the lower thread yields while the higher priority thread
   is scheduled to run 




---- SYNCHRONIZATION ----

>> B6: Describe a potential race in thread_set_priority() and explain
>> how your implementation avoids it.  Can you use a lock to avoid
>> this race?

  A potential race would be changing the value of a thread that is depended on by other threads. For instance, 
changing a the priority of a running thread to be lower than a thread on the ready list should yeild the processor.
Another example would be changing the priority of a thread that is donating its priority to another thread, in which
case you would also want to pass that new value along to the donatee thread.
  Our implementation did not use a lock to solve avoid this race. Instead we turn off interrupts while the 
check for a higher priority thread to run is being run. After the priority of ANY thread is altered, we call 
prioritize() which checks if any thread on the ready list has a higher priority than the running thread, and if
so the running thread yields. 

---- RATIONALE ----

>> B7: Why did you choose this design?  In what ways is it superior to
>> another design you considered?

The initial design we considered used a second integer value in the thread 
struct, which held the non-donated priority. This design quickly fell apart
for both nested donations, and even for dealing with certain cases of multiple
donations. Then a lock-based design was considered, which placed a list of 
donator threads for a particular lock in the lock struct itself, and while this
system does work for single and multiple donations, it also fails when it comes
to nesting, as there is no way to tell if a thread is on multiple lock donator
lists without maintaining a list of locks somewhere.

The design we ended up with, namely a list of donator threads for each thread
with donated priority, and a static list of the donatee threads, is superior in
that it handles nesting forever, and is more efficient than simply scanning 
the entire all_list for threads whose priority needs to be updated. 

			  ADVANCED SCHEDULER
			  ==================

---- DATA STRUCTURES ----

>> C1: Copy here the declaration of each new or changed `struct' or
>> `struct' member, global or static variable, `typedef', or
>> enumeration.  Identify the purpose of each in 25 words or less.

thread.h:
  
  /* Determines how 'nice' thread should be to other theads,
     which is utilized in priority scheduling. */
  int nice; 

  /* Measures how much CPU time the thread has received recently */ 
  int recent_cpu;

thread.c: 

  /* System load average. Estimates the average number of threads ready to run
     over the past minute. Exponentially weighted moving average. */
  int load_avg;
 
  /* Number of threads that are either running or ready to run, not including the idle thread,
     at time of update. */
  int ready_threads

---- ALGORITHMS ----

>> C2: Suppose threads A, B, and C have nice values 0, 1, and 2.  Each
>> has a recent_cpu value of 0.  Fill in the table below showing the
>> scheduling decision and the priority and recent_cpu values for each
>> thread after each given number of timer ticks:

"Thread priority is calculated initially at thread initializaiton"


timer  recent_cpu    priority   thread
ticks   A   B   C   A   B   C   to run
-----  --  --  --  --  --  --   ------
 0	0   0   0  63  61  59     A 	    
 4      4   1   2  62  61  59     A   
 8      7   2   4  62  59  58     A
12      9   3   6  61  61  58     A     
16     12   4   8  60  60  57     A   <-  A & B have equal priorities here 
20     14   5   9  60  60  57     A
24     16   5  10  59  60  57     B
28     14   9  11  60  59  57     A
32     16   9  12  59  59  56     A
36     18   9  13  59  59  56     A 

>> C3: Did any ambiguities in the scheduler specification make values
>> in the table uncertain?  If so, what rule did you use to resolve
>> them?  Does this match the behavior of your scheduler?

  The ambiguity was discovered of what to do when priorities are equal. The table follows the same logic of what 
we used in the scheduler. 
  We test if the current thread has a priority that is lower than the next. In turn, we do not switch threads
when they are equal. If instead we tested for less than or equal the new thread would switch over in a tie. 

>> C4: How is the way you divided the cost of scheduling between code
>> inside and outside interrupt context likely to affect performance?

  As with the other portions of the project, we aim to disable interrupts for the shortest time possible to
increase efficiency. The more often that ticks occur the faster the process can execute its intent. Consequently,
the more lines of code that you have interrupts disabled the more you slow down the overall execution. For instance,
we check to see if we need to run methods outside of the context, and if it is determined that we do need to call a 
method that requires interrupts be disabled, we do so within that method. 


---- RATIONALE ----

>> C5: Briefly critique your design, pointing out advantages and
>> disadvantages in your design choices.  If you were to have extra
>> time to work on this part of the project, how might you choose to
>> refine or improve your design?

  Given the nature of the testing routines, on every interrupt we need to check if thread_mlfqs is true. This is only
one check but it is run so often that the overhead is notable. An alternate strategy would be to have different methods
for interrupts depending on which scheduler you are using. 
  Additionally, the value for the number of threads currently ready didn't need to be a static variable as it could 
have been calculated on the fly when you calculate load average. This was done intentionally for modularity and 
debugging purposes.
  If we had more time to improve the design, one aspect would be to streamline more of the fixed point operations. A lot
of the functionality needed we nest together these statements, where functions that combine the operations would improve 
efficiency. 


>> C6: The assignment explains arithmetic for fixed-point math in
>> detail, but it leaves it open to you to implement it.  Why did you
>> decide to implement it the way you did?  If you created an
>> abstraction layer for fixed-point math, that is, an abstract data
>> type and/or a set of functions or macros to manipulate fixed-point
>> numbers, why did you do so?  If not, why not?

  All of the fixed point arithmetic is contained in fixed-point.h within the threads directory. It made sense for us to
isolate the functionality in its own structure as it may need to be reused in other portions of the project. It is rare 
to find a math library of functionality defined within the context of a program, as it makes more sense to import math 
functions rather than redefine them. 

			   SURVEY QUESTIONS
			   ================

Answering these questions is optional, but it will help us improve the
course in future quarters.  Feel free to tell us anything you
want--these questions are just to spur your thoughts.  You may also
choose to respond anonymously in the course evaluations at the end of
the quarter.

>> In your opinion, was this assignment, or any one of the three problems
>> in it, too easy or too hard?  Did it take too long or too little time?

>> Did you find that working on a particular part of the assignment gave
>> you greater insight into some aspect of OS design?

>> Is there some particular fact or hint we should give students in
>> future quarters to help them solve the problems?  Conversely, did you
>> find any of our guidance to be misleading?

>> Do you have any suggestions for the TAs to more effectively assist
>> students, either for future quarters or the remaining projects?

>> Any other comments?
